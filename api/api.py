from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from datetime import datetime
import time
import os
import json
import google.generativeai as genai
from typing import Optional, Dict, Any
from pydantic import BaseModel
from pymongo import MongoClient
from bson import ObjectId
from config import FILLER_WORDS, IDEAL_WPM, SLOW_THRESHOLD, FAST_THRESHOLD
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

MONGO_URI = os.getenv("MONGO_URI")
DB_NAME = os.getenv("DB_NAME")
COLLECTION_NAME = os.getenv("COLLECTION_NAME")

# Gemini API í‚¤ ì„¤ì •
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
gemini_model = genai.GenerativeModel("gemini-2.0-flash")

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë°°í¬ ì‹œ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ í•„ìš”
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MongoDB ì—°ê²°
mongo_client = MongoClient(MONGO_URI)
db = mongo_client[DB_NAME]
collection = db[COLLECTION_NAME]

# ìš”ì²­ ëª¨ë¸ ì •ì˜
class TextAnalysisRequest(BaseModel):
    session_id: str = "default"
    text: str
    generate_ai_feedback: bool = False

# ì‘ë‹µ ëª¨ë¸ ì •ì˜
class AnalysisResponse(BaseModel):
    success: bool
    analysis: Dict[str, Any]

# MongoDB ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def mongo_to_dict(obj):
    if isinstance(obj, dict):
        return {k: mongo_to_dict(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [mongo_to_dict(item) for item in obj]
    elif isinstance(obj, ObjectId):
        return str(obj)
    return obj

# ====================
# ğŸ“Œ ë¶„ì„ í´ë˜ìŠ¤ ì •ì˜
# ====================
class SpeechAnalyzer:
    def __init__(self):
        self.start_time = time.time()
        self.word_count = 0
        self.filler_counts = {word: 0 for word in FILLER_WORDS}
        self.all_words = []
        self.full_text = ""
        self._session_id = "default"

    def add_text(self, text: str) -> None:
        words = text.strip().split()
        self.word_count += len(words)
        self.all_words.extend(words)
        self.full_text += " " + text.strip()
        self._count_fillers(words)

    def _count_fillers(self, words: list) -> None:
        for word in words:
            word_lower = word.lower().strip('.,!?;:')
            if word_lower in self.filler_counts:
                self.filler_counts[word_lower] += 1

    def get_analysis(self) -> dict:
        minutes = (time.time() - self.start_time) / 60
        wpm = self.word_count / minutes if minutes > 0 else 0

        used_fillers = {k: v for k, v in self.filler_counts.items() if v > 0}

        if wpm < SLOW_THRESHOLD:
            wpm_feedback = "ì¡°ê¸ˆ ë” ë¹ ë¥´ê²Œ ë§ì”€í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
        elif wpm > FAST_THRESHOLD:
            wpm_feedback = "ì¡°ê¸ˆ ë” ì²œì²œíˆ, ë˜ë°•ë˜ë°• ë§ì”€í•´ë³´ì„¸ìš”."
        else:
            wpm_feedback = "ì ì ˆí•œ ì†ë„ë¡œ ë§í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

        return {
            "session_id": self.session_id,
            "full_text": self.full_text.strip(),
            "word_count": self.word_count,
            "wpm": round(wpm, 2),
            "wpm_feedback": wpm_feedback,
            "filler_words": used_fillers,
            "total_fillers": sum(used_fillers.values()),
            "speech_duration": round(time.time() - self.start_time, 2),
            "last_updated": datetime.now().isoformat()
        }

    @property
    def session_id(self):
        return self._session_id

    @session_id.setter
    def session_id(self, value):
        self._session_id = value

# ====================
# ğŸ“Œ AI í”¼ë“œë°± ìƒì„±
# ====================
async def generate_ai_feedback(analysis_result: dict) -> str:
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±"""
    try:
        wpm = analysis_result.get('wpm', 0)
        wpm_feedback = analysis_result.get('wpm_feedback', '')
        total_fillers = analysis_result.get('total_fillers', 0)
        filler_words = analysis_result.get('filler_words', {})
        speech_duration = analysis_result.get('speech_duration', 0)
        full_text = analysis_result.get('full_text', '')
        
        prompt = f"""
        ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ë°œí™” ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ì „ë¬¸ê°€ ê°™ì€ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        
        [ë°œí™” ë‚´ìš©]
        {full_text}
        
        [ë¶„ì„ ê²°ê³¼]
        - í‰ê·  ì†ë„: {wpm} WPM
        - ì†ë„ í”¼ë“œë°±: {wpm_feedback}
        - ì‚¬ìš©ëœ í•„ëŸ¬ ë‹¨ì–´: {total_fillers}íšŒ
        - í•„í„° ë‹¨ì–´ ìƒì„¸: {json.dumps(filler_words, ensure_ascii=False)}
        - ë°œí™” ì‹œê°„: {speech_duration:.2f}ì´ˆ
        
        ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ í•œêµ­ì–´ë¡œ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        1. ë°œí™” ì†ë„ê°€ ì ì ˆí•œì§€ í‰ê°€
        2. í•„ëŸ¬ ë‹¨ì–´ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
        3. ì „ì²´ì ì¸ ë°œí™” íë¦„ê³¼ ëª…í™•ì„± í‰ê°€
        4. ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸
        5. ê²©ë ¤ì˜ ë©”ì‹œì§€ í¬í•¨
        """
        
        response = gemini_model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"AI í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
        return "AI í”¼ë“œë°±ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ====================
# ğŸ“Œ ì„¸ì…˜ & DB ê´€ë¦¬
# ====================

# ì¸ë©”ëª¨ë¦¬ ì„¸ì…˜ ì €ì¥ì†Œ
sessions = {}

# MongoDB ì €ì¥ í•¨ìˆ˜
def save_result_to_db(result: dict) -> dict:
    try:
        # _id í•„ë“œê°€ ìˆìœ¼ë©´ ì œê±° (MongoDBê°€ ìë™ ìƒì„±í•˜ë„ë¡)
        result_copy = result.copy()
        if '_id' in result_copy:
            del result_copy['_id']
            
        # MongoDBì— ì €ì¥
        result_id = collection.insert_one(result_copy).inserted_id
        
        # ì €ì¥ëœ ë¬¸ì„œ ì¡°íšŒ
        saved_doc = collection.find_one({"_id": result_id})
        return mongo_to_dict(saved_doc)
    except Exception as e:
        print(f"MongoDB ì €ì¥ ì‹¤íŒ¨: {e}")
        return result

# ====================
# ğŸ“Œ API ë¼ìš°íŒ…
# ====================

@app.post("/api/analyze", response_model=AnalysisResponse)
async def analyze_text(request: TextAnalysisRequest):
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    if request.session_id not in sessions:
        analyzer = SpeechAnalyzer()
        analyzer.session_id = request.session_id
        sessions[request.session_id] = analyzer

    analyzer = sessions[request.session_id]
    analyzer.add_text(request.text)
    result = analyzer.get_analysis()

    # AI í”¼ë“œë°± ìƒì„± (ìš”ì²­ëœ ê²½ìš°ì—ë§Œ)
    if request.generate_ai_feedback:
        result["ai_feedback"] = await generate_ai_feedback(result)

    # ê²°ê³¼ ì €ì¥
    saved_result = save_result_to_db(result)
    
    return {
        "success": True,
        "analysis": saved_result
    }

@app.post("/api/reset-session")
async def reset_session(session_id: str):
    if session_id in sessions:
        del sessions[session_id]
    return {"success": True, "message": f"ì„¸ì…˜ {session_id} ì´ˆê¸°í™” ì™„ë£Œ"}

@app.get("/api/filler-words")
async def get_filler_words():
    return {
        "success": True,
        "words": FILLER_WORDS
    }

@app.get("/api/session-history/{session_id}")
async def get_session_history(session_id: str):
    try:
        results = list(collection.find({"session_id": session_id}))
        if not results:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ì„¸ì…˜ì˜ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        results = [mongo_to_dict(result) for result in results]
        
        return {
            "success": True,
            "session_id": session_id,
            "history": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DB ì¡°íšŒ ì˜¤ë¥˜: {e}")

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)